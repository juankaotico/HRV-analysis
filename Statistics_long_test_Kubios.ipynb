{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11383a0a-8d7b-420f-a3a4-cbe83ef7170f",
   "metadata": {},
   "source": [
    "# Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1a72d5-abd4-4022-9830-3f2f97b90faa",
   "metadata": {},
   "source": [
    "**Instalation of the packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb38691-d9d4-484e-80f2-1ad37ce99c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install \"statsmodels\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3766908-4502-418a-ae76-13a4180db0e7",
   "metadata": {},
   "source": [
    "## Read and merge files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11d6e6d-0841-4e48-969a-4b4a04c8f1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import statistics\n",
    "import re\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74f0413-e4e8-4ad5-b80b-fa4ec2fbe2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sub1 = pd.read_csv(\"path...\\KubiosHRVresultsSub1.csv\", header = 1) #read data file\n",
    "Sub2 = pd.read_csv(\"path...\\KubiosHRVresultsSub2.csv\", header = 1) #read data file\n",
    "Sub3 = pd.read_csv(\"path...\\KubiosHRVresultsSub3.csv\", header = 1) #read data file\n",
    "#... add all files from Kubios HRV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21d433c-8971-4559-8f30-1d78fe9d090c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([Sub1,Sub2,Sub3], axis = 0) # merge all files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46d71d9-1888-48f3-a1e0-5130b9e5efb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df # visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3fba0e8-526e-4d64-ac31-492f7d6ad33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20]\n",
    "df = df.drop(df.columns[cols],axis=1) # eliminate informational columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6136bd1-bd10-46a2-8ba9-bdd9aa9088af",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=[\"Unnamed: 103\"], inplace=True) # eliminate \"random\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968b8e70-a26a-4968-b10f-3b859ba6a801",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.set_index(\"FileName\") #set the ne indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327a2eba-3b5c-4fa4-8999-ca2b4d4a9761",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Emp = df.filter(like = \"Empatica\", axis = 0)\n",
    "df_Far = df.filter(like = \"Faros\", axis = 0) #divide our datasets depending on the source"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0dacb4-31f3-431f-9e3c-affe052a2a58",
   "metadata": {},
   "source": [
    "## Statistical Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3185aa54-d900-49f3-91f5-29c180ae79a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Emp #visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2f4b53-5582-4ed4-9b33-d95f86077793",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Far #visualize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019dd6bd-f416-4d52-bb62-6fde200daba4",
   "metadata": {},
   "source": [
    "### Mean Difference - Global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae18c26c-da89-4319-a3ab-81982a0a90d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "intro = pd.Index(df_Emp.columns) #create index for iteration process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3d2d91-f125-49cf-bbd6-89836e219020",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "data1 = []\n",
    "data2 = [] #create empty lists to save the data\n",
    "for column in df_Emp.columns: #mean difference between the complete datasets\n",
    "        x = df_Emp[column].astype(float).mean() #list the means of Empatica\n",
    "        y = df_Far[column].astype(float).mean() #list the means of Faros\n",
    "        z = (df_Emp[column].astype(float).mean() - df_Far[column].astype(float).mean()) #list the difference of the means\n",
    "        z = abs (z)\n",
    "        data.append (x)\n",
    "        data1.append (y)\n",
    "        data2.append (z)\n",
    "mean_x = pd.DataFrame (data, index = intro, columns=[\"Means Empatica\"])\n",
    "mean_y = pd.DataFrame (data1, index = intro, columns=[\"Means Faros\"])\n",
    "mean_z = pd.DataFrame (data2, index = intro, columns=[\"Mean Difference\"])\n",
    "#generate df's\n",
    "mean_diff = pd.concat ([mean_x,mean_y,mean_z], axis = 1) #concat our 3 datasets\n",
    "mean_diff.index.name = \"Name\" #give name to the index\n",
    "mean_diff.rename(index=lambda x: x.replace('(',''), inplace=True)\n",
    "mean_diff.rename(index=lambda x: x.replace(')',''), inplace=True) #remove the \"(\" and \")\" 's\n",
    "mean_diff #visualize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24078360-3b68-4a3d-813f-021d792c472e",
   "metadata": {},
   "source": [
    "## Conservative approach with NaN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cec6115-ce10-4761-af4b-278a537b6bc1",
   "metadata": {},
   "source": [
    "Check number of NaN's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f24cd48-ab92-40bf-9708-ef76cdb2b609",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Emp.isnull().sum().sum() #count NaN's in Empatica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb9e5de-6e90-4e32-9a44-f2a3a025ba3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Far.isnull().sum().sum() #count NaN's in Faros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7c9ffe-aa33-489c-8faf-8ac5ded58eaa",
   "metadata": {},
   "source": [
    "Here the idea is to maintain as much data as possible, for this reason we not delete the whole column with NaN values, rather than only\n",
    "the specific value and its counterpart in the other DF (because is not longer possible to do a comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75da9a0f-4658-4365-a35a-c6c0e4aebac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df_Emp.astype(float)\n",
    "df2 = df_Far.astype(float) # transform all our values to floats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d794611c-37fd-4078-94c5-099c8e321a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.rename(columns=lambda x: x.replace('(',''), inplace=True)\n",
    "df1.rename(columns=lambda x: x.replace(')',''), inplace=True) \n",
    "df2.rename(columns=lambda x: x.replace('(',''), inplace=True)\n",
    "df2.rename(columns=lambda x: x.replace(')',''), inplace=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd96240b-38b5-4e7e-84cd-4645ea88d6e7",
   "metadata": {},
   "source": [
    "## Alter the label of our datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f24b5c-b6db-4503-8f8c-13f9ea16784e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.rename(index=lambda x: x.replace('Sub1_Empatica_','Sub1_'), inplace=True)\n",
    "df1.rename(index=lambda x: x.replace('Sub2_Empatica_','Sub2_'), inplace=True)\n",
    "df1.rename(index=lambda x: x.replace('Sub3_Empatica_','Sub3_'), inplace=True)\n",
    "\n",
    "df2.rename(index=lambda x: x.replace('Sub1_Faros_','Sub1_'), inplace=True )\n",
    "df2.rename(index=lambda x: x.replace('Sub2_Faros_','Sub2_'), inplace=True )\n",
    "df2.rename(index=lambda x: x.replace('Sub3_Faros_','Sub3_'), inplace=True )\n",
    "# edit the beginning of the index of our df's, depends of how was save in the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1004f95-7a25-407a-b17d-22085b4cdb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "df12_merged = df1.merge(df2, suffixes=[\" _empatica\", \" _faros\"], on=\"FileName\") # merge the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bbb3a79-5e87-4b02-a71d-3936c7467bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df12_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "825621c7-0e78-4b27-b1b0-b4c6a03ca24c",
   "metadata": {},
   "source": [
    "Fix the names of our columns (remove \"(\" and \")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e541a2a4-ba8a-4cdc-9fe5-0b4c2eb7cb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df12_merged.rename(columns=lambda x: x.replace('(',''), inplace=True)\n",
    "df12_merged.rename(columns=lambda x: x.replace(')',''), inplace=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8324c2d0-ae65-4a38-91de-c8ea83ed9633",
   "metadata": {},
   "source": [
    "Create our working list for itemize in the loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5c03ac-bcc6-449a-a95e-209a7bca0f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = df_Emp #copy one of the original datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437b070b-44ae-4f20-a6fe-d0e306efdc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "w.rename(columns=lambda x: x.replace('(',''), inplace=True)\n",
    "w.rename(columns=lambda x: x.replace(')',''), inplace=True) #remove the \"(\" and \")\" 's to avoid RE expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aca7630-d0c4-430b-916e-1118831568e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = w.columns # create a list for reference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b74ef2-004e-4102-93a9-9731f4493a0c",
   "metadata": {},
   "source": [
    "## Data exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a15ea1b-6d32-42da-b0be-17d906f129f1",
   "metadata": {},
   "source": [
    "We want to explore the distribution of our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac26646-f2bb-47b1-951a-bd4cd835bee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "skew_emp = pd.DataFrame ((df1.loc[ : , df1.columns ].skew(axis = 0, skipna = True)), columns=[\"Skew_Emp\"])\n",
    "skew_emp.index.name = \"HRV metric\" #give name to the index\n",
    "skew_far = pd.DataFrame ((df2.loc[ : , df2.columns ].skew(axis = 0, skipna = True)), columns = [\"Skew_Far\"])\n",
    "skew_far.index.name = \"HRV metric\" #give name to the index\n",
    "skew_tot = skew_emp.merge(skew_far, on = \"HRV metric\")\n",
    "skew_tot #skewness of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a220333c-000a-4cf8-904e-73e3997d2cc9",
   "metadata": {},
   "source": [
    "If the skewness is between -0.5 and 0.5, the data are fairly symmetrical\n",
    "If the skewness is between -1 and – 0.5 or between 0.5 and 1, the data are moderately skewed\n",
    "If the skewness is less than -1 or greater than 1, the data are highly skewed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ca0ffc-e3e1-481e-bf22-92c809a3ce4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "skew_tot.loc[ abs(skew_tot[\"Skew_Emp\"]) > 0.5] # number of values moderately skewed for Empatica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcaee566-3846-4735-af2a-fd5d7d2f506d",
   "metadata": {},
   "outputs": [],
   "source": [
    "skew_tot.loc[ abs(skew_tot[\"Skew_Emp\"]) > 1] # number of values highly skewed for Empatica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367e1540-9656-4015-a915-cf91771dcd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "skew_tot.loc[ abs(skew_tot[\"Skew_Far\"]) > 0.5] # number of values moderately skewed for Empatica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e254a734-0952-4100-b15c-56c049cd7a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "skew_tot.loc[ abs(skew_tot[\"Skew_Far\"]) > 1] # number of values highly skewed for Empatica"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2e4d2a-fcfb-41f7-a9d2-00a7ab592227",
   "metadata": {},
   "source": [
    "### Evaluate the normallity of our dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4ab302-cac4-496b-a4ea-79d577aa92d1",
   "metadata": {},
   "source": [
    "We can also explore the distribution with Shapiro-Wilk test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350307c2-85a5-46f5-99ce-c6296050ac15",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap1 = []\n",
    "s_val_p1 = []\n",
    "colnew_s1 =[] #create empty lists to save the data\n",
    "for column in column_names: #iterate in our reference list\n",
    "        x = df1.filter(like=column) #filter from the combine dataset only the columns that start with the \"name\" at a time\n",
    "        x = x.dropna() #drop the NaN for the specified duplet\n",
    "        if len(x) > 2: # setting a threshold of at least 3 values\n",
    "            r, p = stats.shapiro(x) #shapiro test\n",
    "            shap1.append (r)\n",
    "            s_val_p1.append (p)\n",
    "            colnew_s1.append (column) # add the specified values to the list\n",
    "res_shap1 = pd.DataFrame (shap1, columns=[\"Shap_statistics_emp\"])\n",
    "res_shap2 = pd.DataFrame (s_val_p1, columns=[\"P-value(Shap_stats_emp)\"])\n",
    "res_shap3 = pd.DataFrame (colnew_s1, columns=[\"Name\"]) # create df from lists\n",
    "shap_stats1 = pd.concat([res_shap1,res_shap2,res_shap3], axis =1) #merge into one\n",
    "\n",
    "\n",
    "shap2 = []\n",
    "s_val_p2 = []\n",
    "colnew_s2 =[] #create empty lists to save the data\n",
    "for column in column_names: #iterate in our reference list\n",
    "        x = df2.filter(like=column) #filter from the combine dataset only the columns that start with the \"name\" at a time\n",
    "        x = x.dropna() #drop the NaN for the specified duplet\n",
    "        if len(x) > 2: # setting a threshold of at least 3 values\n",
    "            r, p = stats.shapiro(x) #shapiro test\n",
    "            shap2.append (r)\n",
    "            s_val_p2.append (p)\n",
    "            colnew_s2.append (column) # add the specified values to the list\n",
    "res_shap4 = pd.DataFrame (shap2, columns=[\"Shap_statistics_far\"])\n",
    "res_shap5 = pd.DataFrame (s_val_p2, columns=[\"P-value(Shap_stats_far)\"])\n",
    "res_shap6 = pd.DataFrame (colnew_s2, columns=[\"Name\"]) # create df from lists\n",
    "shap_stats2 = pd.concat([res_shap4,res_shap5,res_shap6], axis =1) #merge into one\n",
    "\n",
    "\n",
    "shap_stats_tot = pd.merge(shap_stats1, shap_stats2, how= \"outer\", on=\"Name\")  #merge both files\n",
    "shap_stats_tot.set_index(\"Name\", inplace = True)\n",
    "shap_stats_tot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25477dc9-bb61-451f-ab2f-560b4eeccc49",
   "metadata": {},
   "source": [
    "### Pearson correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9663e3e6-4389-48c9-9e5d-db7bdb922cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = []\n",
    "p_val_p = []\n",
    "colnew_p =[] #create empty lists to save the data\n",
    "for column in column_names: #iterate in our reference list\n",
    "        x = df12_merged.filter(like=column) #filter from the combine dataset only the columns that start with the \"name\" at a time\n",
    "        x = x.dropna() #drop the NaN for the specified duplet\n",
    "        if len(x) > 2: # setting a threshold of at least 3 values\n",
    "                r, p = stats.pearsonr(x[x.columns[0]], x[x.columns[1]]) #Pearson correlation\n",
    "                corr.append (r)\n",
    "                p_val_p.append (p)\n",
    "                colnew_p.append (column) # add the specified values to the list\n",
    "res_per1 = pd.DataFrame (corr, columns=[\"Pearson_correlation_value\"])\n",
    "res_per2 = pd.DataFrame (p_val_p, columns=[\"P-value(Pear-corr)\"])\n",
    "res_per3 = pd.DataFrame (colnew_p, columns=[\"Name\"]) # create df from lists\n",
    "per_corr = pd.concat([res_per1,res_per2,res_per3], axis =1) #merge into one\n",
    "per_corr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a259b57d-f0a5-4624-9678-5eb94d85a9d2",
   "metadata": {},
   "source": [
    "### Student t-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78681d18-ed82-4c1b-9f66-08f8148f02fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "stut = []\n",
    "p_val_s = []\n",
    "colnew_s =[]#create empty lists to save the data\n",
    "for column in column_names: #iterate in our reference list\n",
    "        x = df12_merged.filter(like=column) #filter from the combine dataset only the columns that start with the \"name\" at a time\n",
    "        x = x.dropna() #drop the NaN for the specified duplet\n",
    "        if len(x) > 2: # setting a threshold of at least 3 values\n",
    "                r, p = stats.ttest_rel(x[x.columns[0]], x[x.columns[1]]) #paired test\n",
    "                stut.append (r)\n",
    "                p_val_s.append (p)\n",
    "                colnew_s.append (column)# add the specified values to the list\n",
    "res_stut1 = pd.DataFrame (stut, columns=[\"T-test_value\"])\n",
    "res_stut2 = pd.DataFrame (p_val_s, columns=[\"P-value(T-Test)\"])\n",
    "res_stut3 = pd.DataFrame (colnew_s, columns=[\"Name\"])# create df from lists\n",
    "t_test = pd.concat([res_stut1,res_stut2,res_stut3], axis =1) #merge into one\n",
    "t_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187eaa8a-0866-451b-9e7a-140b7db89f7f",
   "metadata": {},
   "source": [
    "### Wilcoxon Rank test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522ab147-4d02-472b-9d49-19242d887b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "wilc = []\n",
    "p_val_w = []\n",
    "colnew_w =[]#create empty lists to save the data\n",
    "for column in column_names: #iterate in our reference list\n",
    "        x = df12_merged.filter(like=column) #filter from the combine dataset only the columns that start with the \"name\" at a time\n",
    "        x = x.dropna() #drop the NaN for the specified duplet\n",
    "        if len(x) > 2: # setting a threshold of at least 3 values\n",
    "            r, p = stats.wilcoxon(x[x.columns[0]], x[x.columns[1]], alternative='two-sided') #wilcoxon test\n",
    "            wilc.append (r)\n",
    "            p_val_w.append (p)\n",
    "            colnew_w.append (column)# add the specified values to the list\n",
    "res_wilc1 = pd.DataFrame (wilc, columns=[\"Wilconxon_stats\"])\n",
    "res_wilc2 = pd.DataFrame (p_val_w, columns=[\"P-value(Wilcoxon)\"])\n",
    "res_wilc3 = pd.DataFrame (colnew_w, columns=[\"Name\"])# create df from lists\n",
    "wilc_rank = pd.concat([res_wilc1,res_wilc2,res_wilc3], axis =1) #merge into one\n",
    "wilc_rank"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c70b5c7-75d3-455c-b902-05e8046d8ca4",
   "metadata": {},
   "source": [
    "## Create a comparison complete table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba38515e-1a31-42db-b0c6-e4e83fe6f6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "per_corr.set_index(\"Name\", inplace=True)\n",
    "t_test.set_index(\"Name\", inplace=True) # set the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2137c07a-c082-4348-9367-e03b09e137f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "per_corr #visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327db659-541f-40bf-b4f6-97c28c54eb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_test #visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8557fe8b-07fd-4612-804a-6d49e23e3e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_diff #visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b862b9fa-a8c9-402b-938a-4161894c0fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "per_t_compared = pd.merge(per_corr, t_test, how= \"outer\", on=\"Name\") \n",
    "#merge pearson df's using the combine column on name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432224e3-df24-4071-b1c3-79c1b19b1a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "per_t_compared #visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce24ee99-d43f-4c1b-83ff-7e187207e646",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_wilc_compared = pd.merge(per_t_compared, mean_diff, how= \"outer\", on=\"Name\") \n",
    "#merge pearson df's using the combine column on name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e597f559-06af-43d7-96df-669f3f853496",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_compared = pd.merge(non_wilc_compared, wilc_rank, how= \"outer\", on=\"Name\") \n",
    "#merge pearson df's using the combine column on name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097f4e48-207e-4332-bc93-ab4d0872ba77",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_compared #visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b97ba03-a497-45b4-8b1a-44a8a69fee40",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_compared.to_csv(\"path...comparison_table.csv\", decimal=',', sep=';', index = False)\n",
    "#save"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c87dff-6da1-45b4-933d-f90e4af07eb2",
   "metadata": {},
   "source": [
    "### Bland-Altman Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077e7037-45d0-4866-951b-b963d0ec8181",
   "metadata": {},
   "outputs": [],
   "source": [
    "font1 = {'family':'serif','color':'blue','size':20}\n",
    "\n",
    "for column in column_names:\n",
    "    d = df12_merged.filter(like=column)  #filter from the combine dataset only the columns that start with the \"name\" at a time\n",
    "    d = d.dropna() #drop the NaN for the specified duplet\n",
    "    if len(d) > 2:    # setting a threshold of at least 3 values\n",
    "        #create Bland-Altman plot                  \n",
    "        f, ax = plt.subplots(1, figsize = (8,5))\n",
    "        sm.graphics.mean_diff_plot(d[d.columns[0]], d[d.columns[1]], ax = ax)        \n",
    "        plt.title(column, fontdict = font1)\n",
    "        #display Bland-Altman plot\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
