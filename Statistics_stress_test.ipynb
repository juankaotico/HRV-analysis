{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11383a0a-8d7b-420f-a3a4-cbe83ef7170f",
   "metadata": {},
   "source": [
    "# Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3766908-4502-418a-ae76-13a4180db0e7",
   "metadata": {},
   "source": [
    "## Read and merge files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11d6e6d-0841-4e48-969a-4b4a04c8f1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import statistics\n",
    "import re\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f654f28-5ef2-4b4f-92d6-b97d73b19589",
   "metadata": {},
   "source": [
    "#### 1st rest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775c76c7-c1dc-4c71-92b2-97070f378ef9",
   "metadata": {},
   "source": [
    "These files come from the first rest section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1dba96-2e1e-44b3-8b58-591d7e5dd03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sub11 = pd.read_csv(\"path...\\KubiosHRVresults1_1.csv\", header = 1) \n",
    "Sub12 = pd.read_csv(\"path...\\KubiosHRVresults1_2.csv\", header = 1) #read the data\n",
    "#... add all files from Kubios HRV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e925a158-6ec1-4657-b786-f51bf00cbaa2",
   "metadata": {},
   "source": [
    "##### Change the name of subjects (avoid duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a4552e-313e-43c5-8c14-3a419af45570",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sub11 = Sub11.set_index(\"FileName\") \n",
    "Sub12 = Sub12.set_index(\"FileName\") #Change the index\n",
    "#... do changes in all the df's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a44bf1-9f01-4206-bb9f-03c29fd2ce2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sub11.rename(index=lambda x: x.replace('Sub1','Sub11'), inplace=True)\n",
    "Sub12.rename(index=lambda x: x.replace('Sub2','Sub12'), inplace=True) #rename the subjects\n",
    "#... do changes in all the df's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0878af4b-b72e-4d3d-9032-eefd68eed11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sub11.reset_index(inplace=True)\n",
    "Sub12.reset_index(inplace=True) #add the int index for future filtering\n",
    "#... do changes in all the df's"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bcf6a79-b0fc-4e4b-bbb9-91b1d2d7481d",
   "metadata": {},
   "source": [
    "#### 2nd rest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035e0daa-f961-49ce-b697-deb1ba55f4c6",
   "metadata": {},
   "source": [
    "These files come from the first rest section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74f0413-e4e8-4ad5-b80b-fa4ec2fbe2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sub21 = pd.read_csv(\"path...\\KubiosHRVresults2_1.csv\", header = 1)\n",
    "Sub22 = pd.read_csv(\"path...\\KubiosHRVresults2_1.csv\", header = 1) #read the data\n",
    "#... add all files from Kubios HRV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3748ff-33b0-40bf-8237-434bbd589d6c",
   "metadata": {},
   "source": [
    "##### Change the name of subjects (avoid duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d4778b-23a8-4df9-abb1-4bb2cedda1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sub21 = Sub21.set_index(\"FileName\") \n",
    "Sub22 = Sub22.set_index(\"FileName\") #Change the index\n",
    "#... do changes in all the df's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6439e6d5-d346-4e19-9d68-5fa9244a2e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sub21.rename(index=lambda x: x.replace('Sub1','Sub21'), inplace=True)\n",
    "Sub22.rename(index=lambda x: x.replace('Sub2','Sub22'), inplace=True) #rename the subjects\n",
    "#... do changes in all the df's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4473c18-4798-48d6-a936-cf799e8bef01",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sub21.reset_index(inplace=True)\n",
    "Sub22.reset_index(inplace=True) #add the int index for future filtering\n",
    "#... do changes in all the df's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21d433c-8971-4559-8f30-1d78fe9d090c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([Sub11,Sub12,Sub21,Sub22], axis = 0) # merge all files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46d71d9-1888-48f3-a1e0-5130b9e5efb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df # visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3fba0e8-526e-4d64-ac31-492f7d6ad33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20]\n",
    "df = df.drop(df.columns[cols],axis=1) # eliminate informational columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6136bd1-bd10-46a2-8ba9-bdd9aa9088af",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=[\"Unnamed: 103\"], inplace=True) # eliminate \"random\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2ca116-4f8c-4016-aa71-d51192b41219",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_index(ascending=True) #sort the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4033b7ef-8777-48bb-a682-6309f604e67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.loc[df.index==0] # divide according to the source into df's (empatica)\n",
    "df2 = df.loc[df.index==1] # divide according to the source into df's (faros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968b8e70-a26a-4968-b10f-3b859ba6a801",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.set_index(\"FileName\") \n",
    "df2 = df2.set_index(\"FileName\") #set the new indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facc0031-4f8d-4ca6-b14c-8e892d0926b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 #visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a20f24b-169b-46e7-8a38-b74ff1871c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 #visualize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0dacb4-31f3-431f-9e3c-affe052a2a58",
   "metadata": {},
   "source": [
    "## Statistical Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019dd6bd-f416-4d52-bb62-6fde200daba4",
   "metadata": {},
   "source": [
    "### Mean Difference - Global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e05b993-5ae1-4df7-954b-d610a9d91bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in df1.columns: #mean difference between the complete datasets\n",
    "        x = (df1[column].astype(float).mean() - df2[column].astype(float).mean()) \n",
    "        x = abs (x)\n",
    "        print(\"The Mean Difference in {} is {}.\".format(column, x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450a3efe-b210-4f2d-94b8-8f719f651bf6",
   "metadata": {},
   "source": [
    "<p><br>\n",
    "\n",
    " **Due to the existance of several NaN values, it is important to deal with them for the further calculations. Here we show 2 approaches:**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c2a8ad-e070-48a2-8aea-2ffcd0973a63",
   "metadata": {},
   "source": [
    "## Drop all NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c362e4d1-aec4-4473-a73d-4e15d453d490",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_min = df1.astype(float).dropna(axis=1)\n",
    "df2_min = df2.astype(float).dropna(axis=1) # form new dataframes with columns that have all the values a.k.a. exclude all NaN's"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5e3487-05e8-426e-ad18-3ad76deba03b",
   "metadata": {},
   "source": [
    "<p><br>\n",
    "Decide which dataset we will use for reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d54a60-288c-4906-b50a-bd84e3bc19f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_min.columns.isin(df2_min.columns) #check the existance of df1 columns in df2 = all of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d37e6c4-57ec-4929-b905-8381f6b818a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_min.columns.isin(df1_min.columns) #check the existance of df2 columns in df1 = Not all of them"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ffe309f-a55f-4422-b39d-11396590e8d3",
   "metadata": {},
   "source": [
    "<p><br>\n",
    "We take then df1_min as our reference list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09b3727-519a-4a6d-b011-5ce657e1d6cf",
   "metadata": {},
   "source": [
    "### Pearson correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb05c450-7937-4388-9e6f-3970f0cf85d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in df1_min.columns:\n",
    "        r, p = stats.pearsonr(df1_min[column], df2_min[column]) #pearson correlation\n",
    "        print(\"The correlation coefficient in {} is {} and the p-value {}.\".format(column, r, p))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b43e3f9-6466-49a6-a733-b5ef92a7b657",
   "metadata": {},
   "source": [
    "### Student t-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14c9e80-b28b-4488-aa7d-ea17f54e14fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in df1_min.columns:\n",
    "        r, p = stats.ttest_rel(df1_min[column], df2_min[column]) #paired ttest\n",
    "        print(\"The T-Score in {} is {} and the p-value {}.\".format(column, r, p))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24078360-3b68-4a3d-813f-021d792c472e",
   "metadata": {},
   "source": [
    "## Conservative approach with NaN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7c9ffe-aa33-489c-8faf-8ac5ded58eaa",
   "metadata": {},
   "source": [
    "Here the idea is to maintain as much data as possible, for this reason we not delete the whole column with NaN values, rather than only\n",
    "the specific value and its counterpart in the other DF (because is not longer possible to do a comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49160239-fb89-41f4-b053-cb68ee3d8791",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_max = df1.astype(float)\n",
    "df2_max = df2.astype(float) # create new datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25fb2764-a16c-49d2-9784-08f15a7805a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_max.rename(index=lambda x: x.replace('_empatica',''), inplace=True)\n",
    "df2_max.rename(index=lambda x: x.replace('_faros',''), inplace=True) #delete the subfix for the index filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44536608-d563-4864-9ea5-aac8c52f4e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_max #visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d666558-3b5c-4c45-acf8-af8a649549b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = df1_max.merge(df2_max, suffixes=[\" _empatica\", \" _faros\"], on=\"FileName\") \n",
    "#merge both dataframe horizontally and add the suffixes to the columns where they originally came from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730f6042-1a70-4a5a-a200-65dd30df5e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged #visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e541a2a4-ba8a-4cdc-9fe5-0b4c2eb7cb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = df1_max.columns #we create our reference list of indeces for the analisys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5c03ac-bcc6-449a-a95e-209a7bca0f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.DataFrame(column_names) # transform our list into a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d5672a-b69b-4210-9834-75e7fc0c9371",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the dataframe contain names with brakets which make them not viable for using the the regex comand, therefore, we need to drop the brakets\n",
    "# we define a function\n",
    "def Clean_names(Names): \n",
    "    if re.search('\\(.*', Names): # Search for opening bracket in the name followed by any characters repeated any number of times    \n",
    "        pos = re.search('\\(.*', Names).start() # Extract the position of beginning of pattern      \n",
    "        return Names[:pos]  # return the cleaned name\n",
    "    else:        \n",
    "        return Names # if clean up needed return the same name\n",
    "          \n",
    "# Updated the names columns\n",
    "column_names1 = x[x.columns[0]].apply(Clean_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64614ecf-4065-4cc9-964c-9e94e3d2e936",
   "metadata": {},
   "source": [
    "### Pearson correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f681a8d-0547-4f08-bf08-27f3857fa26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in column_names1:\n",
    "    d = df_merged.filter(regex=column) #filter from the combine dataset only the columns that start with the \"name\" at a time\n",
    "    d = d.dropna() #drop the NaN for the specified duplet\n",
    "    if len(d) > 2: # setting a threshold of at least 3 values\n",
    "        r, p = stats.pearsonr(d[d.columns[0]], d[d.columns[1]]) #Pearson correlation\n",
    "        print(\"The correlation coefficient in {} is {} and the p-value {}.\".format(column, r, p))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c97d2e-143e-48da-baf4-050819a2df8c",
   "metadata": {},
   "source": [
    "### Student t-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5e4603-4415-49fb-9bc9-572007e4495b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in column_names1:\n",
    "    d = df_merged.filter(regex=column)  #filter from the combine dataset only the columns that start with the \"name\" at a time\n",
    "    d = d.dropna() #drop the NaN for the specified duplet\n",
    "    if len(d) > 2:    # setting a threshold of at least 3 values\n",
    "        r, p = stats.ttest_rel(d[d.columns[0]], d[d.columns[1]]) #paired ttest\n",
    "        print(\"The T-Score in {} is {} and the p-value {}.\".format(column, r, p))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6fef126-29e2-4ac2-802b-55988524f1ae",
   "metadata": {},
   "source": [
    "### Bland-Altman Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f79ca6-d467-4422-9713-0aed92dfe1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "font1 = {'family':'serif','color':'blue','size':20}\n",
    "\n",
    "for column in column_names1:\n",
    "    d = df_merged.filter(regex=column)  #filter from the combine dataset only the columns that start with the \"name\" at a time\n",
    "    d = d.dropna() #drop the NaN for the specified duplet\n",
    "    if len(d) > 2:    # setting a threshold of at least 3 values\n",
    "#create Bland-Altman plot                  \n",
    "        f, ax = plt.subplots(1, figsize = (8,5))\n",
    "        sm.graphics.mean_diff_plot(d[d.columns[0]], d[d.columns[1]], ax = ax)\n",
    "        plt.title(column, fontdict = font1)\n",
    "\n",
    "#display Bland-Altman plot\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
